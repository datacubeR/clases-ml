{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging y Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Bagging.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder, TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display = 'diagram')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando un modelo Predictivo en el Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Signing_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1911-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1911-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1911-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1911-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1911-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1911-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>1911-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1912-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>1911-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1911-10-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "...               ...     ...   \n",
       "887                 0       2   \n",
       "888                 1       1   \n",
       "889                 0       3   \n",
       "890                 1       1   \n",
       "891                 0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "887                                      Montvila, Rev. Juozas    male  27.0   \n",
       "888                               Graham, Miss. Margaret Edith  female  19.0   \n",
       "889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "890                                      Behr, Mr. Karl Howell    male  26.0   \n",
       "891                                        Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "PassengerId                                                           \n",
       "1                1      0         A/5 21171   7.2500   NaN        S   \n",
       "2                1      0          PC 17599  71.2833   C85        C   \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "4                1      0            113803  53.1000  C123        S   \n",
       "5                0      0            373450   8.0500   NaN        S   \n",
       "...            ...    ...               ...      ...   ...      ...   \n",
       "887              0      0            211536  13.0000   NaN        S   \n",
       "888              0      0            112053  30.0000   B42        S   \n",
       "889              1      2        W./C. 6607  23.4500   NaN        S   \n",
       "890              0      0            111369  30.0000  C148        C   \n",
       "891              0      0            370376   7.7500   NaN        Q   \n",
       "\n",
       "            Signing_date  \n",
       "PassengerId               \n",
       "1             1911-05-17  \n",
       "2             1911-07-23  \n",
       "3             1911-09-08  \n",
       "4             1911-06-26  \n",
       "5             1911-10-25  \n",
       "...                  ...  \n",
       "887           1911-08-17  \n",
       "888           1911-08-07  \n",
       "889           1912-01-30  \n",
       "890           1911-08-08  \n",
       "891           1911-10-27  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic.csv', index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       int64\n",
       "Pclass      category\n",
       "Sex         category\n",
       "Age          float64\n",
       "SibSp          int64\n",
       "Parch          int64\n",
       "Fare         float64\n",
       "Embarked    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = ['Signing_date','Cabin','Ticket','Name'])\n",
    "df[['Pclass','Sex','Embarked']] = df[['Pclass','Sex','Embarked']].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = 'Survived'), df.Survived, test_size = 0.3, random_state = 123)\n",
    "is_cat = X_train.dtypes == 'category'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression / Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.827     0.847     0.837       379\n",
      "           1      0.753     0.725     0.739       244\n",
      "\n",
      "    accuracy                          0.799       623\n",
      "   macro avg      0.790     0.786     0.788       623\n",
      "weighted avg      0.798     0.799     0.799       623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.843     0.824     0.833       170\n",
      "           1      0.706     0.735     0.720        98\n",
      "\n",
      "    accuracy                          0.791       268\n",
      "   macro avg      0.775     0.779     0.777       268\n",
      "weighted avg      0.793     0.791     0.792       268\n",
      "\n",
      "Wall time: 113 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fata2810\\AppData\\Local\\Continuum\\anaconda3\\envs\\MLprojects\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat = Pipeline(steps = [\n",
    "    ('imp_cat', SimpleImputer(strategy = 'most_frequent')), \n",
    "    ('enc', OneHotEncoder())\n",
    "])\n",
    "\n",
    "num = Pipeline(steps = [\n",
    "    ('imp_num', SimpleImputer(strategy = 'mean')), \n",
    "    ('sc', StandardScaler())\n",
    "])\n",
    "\n",
    "prep = ColumnTransformer(transformers = [\n",
    "    ('cat', cat, is_cat), \n",
    "    ('num', num, ~is_cat)\n",
    "])\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('prep', prep), \n",
    "    ('rf', LogisticRegression(random_state = 123))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_train = pipe.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_train, digits = 3))\n",
    "print(classification_report(y_test, y_pred, digits = 3))\n",
    "\n",
    "\n",
    "### Ojo que logramos un acuracy muy parecido a lo que logramos con el Decision Tree pero sin sobreajustar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "Se realiza un ensamble de Regresiones Lineales en la cual se utilizarán 20 regresiones combinadas con Bagging a modo de regularizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.822     0.863     0.842       379\n",
      "           1      0.769     0.709     0.738       244\n",
      "\n",
      "    accuracy                          0.803       623\n",
      "   macro avg      0.795     0.786     0.790       623\n",
      "weighted avg      0.801     0.803     0.801       623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.838     0.853     0.845       170\n",
      "           1      0.737     0.714     0.725        98\n",
      "\n",
      "    accuracy                          0.802       268\n",
      "   macro avg      0.787     0.784     0.785       268\n",
      "weighted avg      0.801     0.802     0.802       268\n",
      "\n",
      "Wall time: 213 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat = Pipeline(steps = [\n",
    "    ('imp_cat', SimpleImputer(strategy = 'most_frequent')), \n",
    "    ('enc', OneHotEncoder())\n",
    "])\n",
    "\n",
    "num = Pipeline(steps = [\n",
    "    ('imp_num', SimpleImputer(strategy = 'mean')), \n",
    "    ('sc', StandardScaler())\n",
    "])\n",
    "\n",
    "prep = ColumnTransformer(transformers = [\n",
    "    ('cat', cat, is_cat), \n",
    "    ('num', num, ~is_cat)\n",
    "])\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('prep', prep), \n",
    "    ('rf', BaggingClassifier(base_estimator = LogisticRegression(), n_estimators = 20, random_state = 123, max_samples = 0.8, n_jobs = -1, max_features = 0.6))\n",
    "])\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_train = pipe.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_train, digits = 3))\n",
    "print(classification_report(y_test, y_pred, digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "\n",
    "Implementación básica de un Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       379\n",
      "           1       0.98      0.99      0.98       244\n",
      "\n",
      "    accuracy                           0.99       623\n",
      "   macro avg       0.99      0.99      0.99       623\n",
      "weighted avg       0.99      0.99      0.99       623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       170\n",
      "           1       0.73      0.73      0.73        98\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.79      0.79      0.79       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = Pipeline(steps = [\n",
    "    ('imp_cat', SimpleImputer(strategy = 'most_frequent')), \n",
    "    ('OneHotEncoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "num = Pipeline(steps = [\n",
    "    ('imp_num', SimpleImputer(strategy = 'mean')), \n",
    "    ('sc', StandardScaler())\n",
    "])\n",
    "\n",
    "prep = ColumnTransformer(transformers = [\n",
    "    ('cat', cat, is_cat), \n",
    "    ('num', num, ~is_cat)\n",
    "])\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('prep', prep), \n",
    "    ('rf', RandomForestClassifier(random_state = 123, n_jobs = -1))\n",
    "])\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_train = pipe.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación RF avanzado\n",
    "\n",
    "Se implementa un modelo de Random Forest más avanzado en el cual se realiza un GridSearch para encontrar parámetros óptimos.\n",
    "\n",
    "Se presentan varios resultados mostrando el efecto de diversa combinación de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat = Pipeline(steps = [\n",
    "    ('imp_cat', SimpleImputer(strategy = 'most_frequent')), \n",
    "    ('enc', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "num = Pipeline(steps = [\n",
    "    ('imp_num', SimpleImputer(strategy = 'mean')), \n",
    "    ('sc', StandardScaler())\n",
    "])\n",
    "\n",
    "prep = ColumnTransformer(transformers = [\n",
    "    ('cat', cat, is_cat), \n",
    "    ('num', num, ~is_cat)\n",
    "])\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    ('prep', prep), \n",
    "    ('rf', RandomForestClassifier(random_state = 123, n_jobs = -1, oob_score = True))\n",
    "])\n",
    "\n",
    "params = {#'prep__num__sc': [StandardScaler(), 'passthorugh'],\n",
    "        #'rf__criterion': ['gini', 'entropy'],\n",
    "        #'prep__cat__enc': [OneHotEncoder(use_cat_names = True), OrdinalEncoder(), TargetEncoder()],\n",
    "        'rf__ccp_alpha': [0.001, 0.01,0.1],#[0.1, 0.3, 0.5], #[0.001, 0.01,0.1]\n",
    "        'rf__max_depth': [1, 5, 10],\n",
    "        'rf__n_estimators': [300, 500],\n",
    "        #'rf__min_samples_split': [0.01, 0.1]\n",
    "         }\n",
    "\n",
    "#params1 = {}\n",
    "\n",
    "search = GridSearchCV(pipe, params, cv = 5, scoring = 'f1', n_jobs = -1)\n",
    "\n",
    "#probar sólo con Scaling y sin escaling\n",
    "# probar distintos encoders\n",
    "# probar con distintos alpha mayores a 0.1\n",
    "# acortar la complejidad del arbol con max_depth sin utilizar ccp_alpha, luego dejar con sólo valores menores a 1\n",
    "# agrandar el bagging usando más estimadores\n",
    "# probar si es que min_samples_split ayuda un poco más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       379\n",
      "           1       0.98      0.99      0.98       244\n",
      "\n",
      "    accuracy                           0.99       623\n",
      "   macro avg       0.99      0.99      0.99       623\n",
      "weighted avg       0.99      0.99      0.99       623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       170\n",
      "           1       0.73      0.73      0.73        98\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.79      0.79      0.79       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_train, digits = 3))\n",
    "print(classification_report(y_test, y_pred, digits = 3))\n",
    "\n",
    "#probar sólo con Scaling y sin escaling, overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       379\n",
      "           1       0.74      0.68      0.71       244\n",
      "\n",
      "    accuracy                           0.78       623\n",
      "   macro avg       0.77      0.76      0.77       623\n",
      "weighted avg       0.78      0.78      0.78       623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       170\n",
      "           1       0.74      0.69      0.72        98\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.78      0.78      0.78       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_train, digits = 3))\n",
    "print(classification_report(y_test, y_pred, digits = 3))\n",
    "\n",
    "# posiblemente óptimo o aun underfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.987     0.989       379\n",
      "           1      0.980     0.988     0.984       244\n",
      "\n",
      "    accuracy                          0.987       623\n",
      "   macro avg      0.986     0.987     0.987       623\n",
      "weighted avg      0.987     0.987     0.987       623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.840     0.865     0.852       170\n",
      "           1      0.753     0.714     0.733        98\n",
      "\n",
      "    accuracy                          0.810       268\n",
      "   macro avg      0.796     0.789     0.793       268\n",
      "weighted avg      0.808     0.810     0.809       268\n",
      "\n",
      "Wall time: 2.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_train, digits = 3))\n",
    "print(classification_report(y_test, y_pred, digits = 3))\n",
    "# distintos encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.812     0.947     0.875       379\n",
      "           1      0.890     0.660     0.758       244\n",
      "\n",
      "    accuracy                          0.835       623\n",
      "   macro avg      0.851     0.804     0.816       623\n",
      "weighted avg      0.842     0.835     0.829       623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.839     0.947     0.890       170\n",
      "           1      0.882     0.684     0.770        98\n",
      "\n",
      "    accuracy                          0.851       268\n",
      "   macro avg      0.860     0.815     0.830       268\n",
      "weighted avg      0.854     0.851     0.846       268\n",
      "\n",
      "Wall time: 5.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_train, digits = 3))\n",
    "print(classification_report(y_test, y_pred, digits = 3))\n",
    "\n",
    "# posiblemente otro óptimo o aun underfitted, es posible quizás sacarle más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.950     0.889       379\n",
      "           1      0.901     0.709     0.794       244\n",
      "\n",
      "    accuracy                          0.856       623\n",
      "   macro avg      0.868     0.829     0.841       623\n",
      "weighted avg      0.861     0.856     0.852       623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.834     0.947     0.887       170\n",
      "           1      0.880     0.673     0.763        98\n",
      "\n",
      "    accuracy                          0.847       268\n",
      "   macro avg      0.857     0.810     0.825       268\n",
      "weighted avg      0.851     0.847     0.842       268\n",
      "\n",
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_train, digits = 3))\n",
    "print(classification_report(y_test, y_pred, digits = 3))\n",
    "\n",
    "#subir n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.950     0.889       379\n",
      "           1      0.901     0.709     0.794       244\n",
      "\n",
      "    accuracy                          0.856       623\n",
      "   macro avg      0.868     0.829     0.841       623\n",
      "weighted avg      0.861     0.856     0.852       623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.834     0.947     0.887       170\n",
      "           1      0.880     0.673     0.763        98\n",
      "\n",
      "    accuracy                          0.847       268\n",
      "   macro avg      0.857     0.810     0.825       268\n",
      "weighted avg      0.851     0.847     0.842       268\n",
      "\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_train, digits = 3))\n",
    "print(classification_report(y_test, y_pred, digits = 3))\n",
    "# modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_rf__ccp_alpha</th>\n",
       "      <th>param_rf__max_depth</th>\n",
       "      <th>param_rf__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.161400</td>\n",
       "      <td>0.247645</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.026874</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'rf__ccp_alpha': 0.001, 'rf__max_depth': 5, '...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.754889</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.975599</td>\n",
       "      <td>0.141807</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.029526</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'rf__ccp_alpha': 0.001, 'rf__max_depth': 5, '...</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.749187</td>\n",
       "      <td>0.019740</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.692174</td>\n",
       "      <td>0.275891</td>\n",
       "      <td>0.361600</td>\n",
       "      <td>0.054481</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'rf__ccp_alpha': 0.01, 'rf__max_depth': 5, 'r...</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.746909</td>\n",
       "      <td>0.029501</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.209053</td>\n",
       "      <td>0.140062</td>\n",
       "      <td>0.392806</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'rf__ccp_alpha': 0.01, 'rf__max_depth': 5, 'r...</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.029989</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.377199</td>\n",
       "      <td>0.187441</td>\n",
       "      <td>0.281001</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'rf__ccp_alpha': 0.01, 'rf__max_depth': 10, '...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.743611</td>\n",
       "      <td>0.028735</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3        3.161400      0.247645         0.287400        0.026874   \n",
       "2        1.975599      0.141807         0.204200        0.029526   \n",
       "9        3.692174      0.275891         0.361600        0.054481   \n",
       "8        2.209053      0.140062         0.392806        0.030942   \n",
       "11       3.377199      0.187441         0.281001        0.011611   \n",
       "\n",
       "   param_rf__ccp_alpha param_rf__max_depth param_rf__n_estimators  \\\n",
       "3                0.001                   5                    500   \n",
       "2                0.001                   5                    300   \n",
       "9                 0.01                   5                    500   \n",
       "8                 0.01                   5                    300   \n",
       "11                0.01                  10                    500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "3   {'rf__ccp_alpha': 0.001, 'rf__max_depth': 5, '...           0.777778   \n",
       "2   {'rf__ccp_alpha': 0.001, 'rf__max_depth': 5, '...           0.772727   \n",
       "9   {'rf__ccp_alpha': 0.01, 'rf__max_depth': 5, 'r...           0.795455   \n",
       "8   {'rf__ccp_alpha': 0.01, 'rf__max_depth': 5, 'r...           0.795455   \n",
       "11  {'rf__ccp_alpha': 0.01, 'rf__max_depth': 10, '...           0.786517   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "3            0.717391           0.744186           0.776471   \n",
       "2            0.717391           0.744186           0.767442   \n",
       "9            0.709677           0.729412           0.761905   \n",
       "8            0.709677           0.729412           0.761905   \n",
       "11           0.702128           0.729412           0.761905   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "3            0.758621         0.754889        0.022469                1  \n",
       "2            0.744186         0.749187        0.019740                2  \n",
       "9            0.738095         0.746909        0.029501                3  \n",
       "8            0.731707         0.745631        0.029989                4  \n",
       "11           0.738095         0.743611        0.028735                5  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_).sort_values(by = 'rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8170144462279294"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.named_steps.rf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Se muestra el mecanismo de rescate de Feature Importance para un Random Forest embebido en un Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex         0.424795\n",
       "Embarked    0.185981\n",
       "SibSp       0.132018\n",
       "Pclass      0.129398\n",
       "Parch       0.054344\n",
       "Fare        0.038931\n",
       "Age         0.034533\n",
       "dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(best_model.named_steps.rf.feature_importances_, X_train.columns).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingresar al Pipeline y extraer valores de Imputación Numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.88569106,  0.51685393,  0.36597111, 33.32687159])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.named_steps.prep.named_transformers_.num.named_steps.imp_num.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('MLprojects': conda)",
   "language": "python",
   "name": "python37764bitmlprojectsconda9e66019a9ab047499c0882be49df755b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
